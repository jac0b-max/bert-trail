# 基于 BERT 的恶意评论实时过滤系统 (Chinese Malicious Comment Filter)

本项目实现了一个 **基于 BERT 的中文恶意评论实时过滤系统**。通过对预训练模型 `bert-base-chinese` 进行微调，构建高精度的（恶意）攻击性言论识别模型，用于网络平台中对恶意评论的自动检测与拦截。

---

## 核心技术
- **深度学习框架**: MindSpore 2.2.13
- **自然语言处理库**: MindNLP
- **预训练模型**: BERT-Base-Chinese
- **计算平台**: 昇腾 (Ascend) / GPU / CPU

---

## 一、项目背景与意义

随着网络社交平台的流行，恶意评论（辱骂、地域歧视、人身攻击等）严重污染了网络环境。传统的关键词匹配方案在面对“阴阳怪气”、“谐音变体”及“语义隐藏”的攻击时效果不佳。

这个项目希望构建一个智能化识别方案：
- **实时性**: 支持毫秒级文本分类响应。
- **高精度**: 相比传统方法，显著提升对复杂语境下攻击性言论的识别率。
- **合规性**: 助力平台满足内容安全审计要求，降低运营风险。

---

## 二、技术方案概述

### 1. 模型架构
系统核心采用 **BERT (Bidirectional Encoder Representations from Transformers)** 架构。BERT 通过双向 Transformer 编码器捕获字词间的双向上下文关系，极大地提升了对中文语义的理解深度。



**微调流程：**
1. **Tokenization**: 将输入文本转换为 BERT 专用的 Token ID、Input Mask 及 Segment ID。
2. **Feature Extraction**: 提取 `[CLS]` 位的高维向量作为全句特征表示。
3. **Classification**: 接入全连接层 (Dense Layer) 并通过 Softmax 归一化，输出 3 类标签的概率分布。

### 2. 训练配置
- **优化器**: Adam
- **策略**: 混合精度训练 (Mixed Precision `O1`)，提升昇腾硬件上的吞吐量。
- **早停机制**: 引入 `BestModelCallback`，基于验证集性能自动保存最优权重。

---

## 三、数据集说明

### 1. 数据来源 (合成数据)
本项目使用 **基于 GPT-4 辅助标注构建的合成数据集 (Synthetic Data)**。
- **构建逻辑**: 利用 LLM 模拟多样化的评论场景（如：正常讨论、激烈争论、恶意辱骂、中性咨询）。
- **人工校验**: 对合成样本进行抽样清洗，确保标签 $(0, 1, 2)$ 的语义一致性。

### 2. 标签定义与数据结构
数据集采用 CSV 格式存储，字段包含 `text` (评论内容) 与 `label` (类别)。

| 标签 (Label) | 类别 | 定义与示例 |
| :--- | :--- | :--- |
| **0** | **恶意评论** | 包含人身攻击、辱骂或歧视。*例：“这种店趁早倒闭吧，垃圾质量。”* |
| **1** | **中性言论** | 纯事实陈述、功能咨询。*例：“请问这个产品保修多久？”* |
| **2** | **正面好评** | 表达认可、感谢。*例：“客服非常专业，问题解决很快！”* |

---

## 四、快速开始

### 1. 环境安装
```bash
# 安装 MindSpore (以 x86 2.2.13 为例)
pip install mindspore==2.7.1 -i https://repo.mindspore.cn/pypi/simple --trusted-host repo.mindspore.cn --extra-index-url https://repo.huaweicloud.com/repository/pypi/simple
# 安装 NLP 扩展库
pip install mindnlp pandas scikit-learn# 基于 BERT 的恶意评论实时过滤系统
```

本项目实现了一个 **基于 BERT 的中文恶意评论实时过滤系统**，通过对预训练模型 `bert-base-chinese` 进行微调，构建高精度的攻击性言论识别模型，用于网络平台中对恶意评论的自动检测与拦截。

项目关注 **中文文本中攻击性、辱骂性与不当言论的识别问题**，适用于社区论坛、评论区、内容审核等实际应用场景。

---

### 2. 超参数配置
为了在确保模型精度同时防止过拟合，实验采用了以下参数组合：

| 参数名称 | 配置值 | 作用说明 |
| :--- | :--- | :--- |
| **Max Seq Length** | 128 | 覆盖 95% 以上的社交媒体长评论 |
| **Batch Size** | 32 | 兼顾显存利用率与梯度稳定性 |
| **Learning Rate** | 2e-5 | BERT 微调的黄金学习率，确保平稳收敛 |
| **Optimizer** | Adam | 具有自适应学习率特征的优化器 |
| **Epochs** | 5 | 合成数据集场景下的最优训练轮数 |
| **AMP Level** | O1 | 开启混合精度，提升推理与训练吞吐量 |

---

## 五、技术方案概述

### 1. 模型架构

- 基础模型：`bert-base-chinese`
- 任务类型：文本分类（恶意 / 非恶意，或多级攻击性分类）
- 架构形式：BERT 编码器 + 自定义分类层

在预训练模型基础上进行微调，并针对恶意言论识别任务：

- 优化分类层结构
- 调整损失函数以提升对攻击性语义的区分能力
- 提升模型对隐性攻击、变体表达的鲁棒性

---

### 2. 数据集构建（GPT-4 辅助标注）

#### 数据来源说明

本项目所使用的数据集为 **基于 GPT-4 辅助人工标注构建的中文恶意评论识别数据集**，属于合成数据（Synthetic Data），主要用于模型训练与实验验证。

数据构建流程如下：

1. 使用 GPT-4 生成多样化中文评论文本，覆盖正常言论与攻击性言论
2. 结合人工规则与语义检查，对生成文本进行情感与攻击性标签标注
3. 对样本进行筛选与校验，确保语义与标签一致性

该数据集 **不来源于真实用户评论或公开平台数据**，仅用于教学、实验与系统原型验证。

---

### 3. 数据集结构

数据集以 CSV 格式存储，便于复现与扩展：

```text
data/
├── train.csv   # 训练集
└── test.csv    # 测试集
```
每个 CSV 文件包含如下字段：

| 字段名 | 含义 |
|------|------|
| text | 中文评论文本 |
| label | 评论类别标签 |

---

## 六、训练与实验设置

模型基于预训练模型 `bert-base-chinese` 进行微调，采用监督学习方式完成恶意评论识别任务。主要训练与实验配置如下：

- 预训练模型：bert-base-chinese  
- 模型结构：BERT 编码器 + 自定义分类层  
- 任务类型：文本分类（恶意评论识别）  
- 优化器：Adam  
- 学习率：2e-5  
- Batch Size：32  
- 训练轮数：5 Epochs  

为提升训练效率与数值稳定性，训练过程中启用了混合精度训练（Mixed Precision Training）。

在训练阶段，系统会根据验证集性能自动保存最优模型参数，便于后续推理与部署使用。

---
## 七、系统应用场景

基于 BERT 的恶意评论实时过滤系统可广泛应用于各类内容生成与用户互动平台，典型应用场景包括：

- 社区论坛与评论区的恶意内容自动审核
- 社交媒体平台中的攻击性言论实时过滤
- 新闻、视频及直播平台的评论安全管控
- 内容安全与平台合规辅助系统
- 系统可作为独立模块集成至现有内容发布或审核流程中，实现对恶意评论的实时或准实时检测与拦截，从而有效降低人工审核成本。

---

## 八、注意事项与局限性

- 本项目使用的数据集为 GPT-4 辅助人工标注生成的合成数据（Synthetic Data），不完全等同于真实用户评论分布
- 模型在真实业务场景中的性能仍需结合真实评论数据进行进一步验证与微调
- 对于语义高度隐晦或依赖上下文的攻击性言论，模型仍可能存在一定的识别难度

